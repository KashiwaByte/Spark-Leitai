from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationChain
from langchain.chains import RetrievalQA
from utils.API import Spark_forlangchain
from utils.API import Spark_tools_forlangchain
import gradio as gr
from langchain.prompts import ChatPromptTemplate
from langchain.document_loaders import TextLoader
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
import sentence_transformers
import time
global llm
global conversation_1
global prompt_template

llm = Spark_forlangchain(n=10)
llm_tools = Spark_tools_forlangchain(n=10)

memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=4096)
conversation_1 = ConversationChain(llm=llm)

memory = ConversationSummaryBufferMemory(llm=llm_tools, max_token_limit=4096)
conversation_2 = ConversationChain(llm=llm_tools)

template_1 = """
ç°åœ¨æ˜¯æ­£æ–¹ç«‹è®ºç¯èŠ‚ï¼Œè¯·ä½ å¬å–æ­£æ–¹ç«‹è®ºï¼Œå¹¶é’ˆå¯¹ç«‹è®ºè¿›è¡Œè´¨è¯¢ã€‚æ­£æ–¹ç«‹è®ºå†…å®¹å¦‚ä¸‹ï¼š{text}
è´¨è¯¢éœ€è¦é€æ¡åé©³è§‚ç‚¹å’Œè®ºæ®ï¼Œå¹¶ä¸”è¦ç»™å‡ºè¯¦ç»†çš„ç†ç”±ã€‚
è´¨ç–‘æ•°æ®è®ºæ®è¦ç”¨ä¸Šå¸¸ç”¨çš„æ–¹æ³•å’Œå¥å¼ï¼Œä»æ•°æ®åˆç†æ€§ï¼Œæ ·æœ¬ä»£è¡¨æ€§ï¼Œç»Ÿè®¡æ–¹æ³•ï¼Œæ•°æ®è§£è¯»ç­‰å¤šä¸ªè§’åº¦è¿›è¡Œè€ƒè™‘ã€‚è´¨ç–‘å­¦ç†è®ºæ®è¦ä»æƒå¨æ€§ï¼Œè§£è¯»æ–¹å¼ï¼Œæ˜¯å¦æœ‰å¯¹æŠ—å­¦ç†ç­‰å¤šä¸ªè§’åº¦è¿›è¡Œè€ƒè™‘ã€‚
"""
template_2 = """
ç°åœ¨æ˜¯ä½ çš„ç«‹è®ºç¯èŠ‚ï¼Œä½ éœ€è¦åœ¨ä¸ç”¨æˆ·ç›¸åçš„æŒæ–¹ä¸Šç«‹è®ºï¼Œç»™å‡ºè‡ªå·±çš„è§‚ç‚¹,
ä½ ç«‹è®ºä¼šéµå¾ªä»¥ä¸‹çš„ç«‹è®ºåŸåˆ™ï¼Œæ€»å…±5ä¸ªåŸåˆ™:
1.å®šä¹‰æ˜ç¡®
å¯¹å…³é”®è¯è¿›è¡Œæ˜ç¡®ä¸”åˆç†çš„å®šä¹‰,è¿™æ˜¯å±•å¼€è®ºè¯çš„åŸºç¡€ã€‚
2.æ ‡å‡†æ¸…æ™°
è®¾ç½®å…¬æ­£åˆç†çš„åˆ¤æ–­æ ‡å‡†,æ ‡å‡†è¦å…·ä½“æ˜ç¡®,ä¸ºè®ºç‚¹æ¯”è¾ƒæä¾›ä¾æ®ã€‚ä½ çš„å›ç­”ä¸­å¿…é¡»åŒ…å«æ ‡å‡†ã€‚
3.è®ºç‚¹åŒ¹é…
è®ºç‚¹è¦èƒ½æœ‰æ•ˆæ”¯æ’‘å¹¶å°è¯æ ‡å‡†,ä¸æ ‡å‡†å’Œç«‹åœºé«˜åº¦å¥‘åˆã€‚ä½ çš„å›ç­”ä¸­å¿…é¡»åŒ…å«æ”¯æ’‘å°è¯æ ‡å‡†çš„è®ºç‚¹ã€‚
4.è®ºæ®å…·ä½“
æä¾›å…·ä½“å¯ä¿¡çš„è®ºæ®æ”¯æ’‘æ¯ä¸ªè®ºç‚¹,ä½¿ä¹‹æ›´æœ‰è¯´æœåŠ›ã€‚ä½ çš„è®ºç‚¹å¿…é¡»è¦è®ºæ®æ”¯æ’‘ã€‚
5.æƒ…å¢ƒé€‚ç”¨
å¼•å…¥æƒ…å¢ƒå’Œä¾‹å­,ä½¿å¤æ‚è§‚ç‚¹å®¹æ˜“è¢«å¬ä¼—æ¥å—ã€‚ä½ çš„å›ç­”å¯ä»¥é€‚å½“åŒ…å«æƒ…å¢ƒ
å½“ç”¨æˆ·åé©³ä½ æ—¶ï¼Œä½ éœ€è¦ä¸ä»–è¾©é©³
"""
template_3 = """

"""
template_4 = ""
template_5 = ""
template_6 = ""
prompt_1 = ChatPromptTemplate.from_template(template_1)
prompt_2 = ChatPromptTemplate.from_template(template_2)
prompt_3 = ChatPromptTemplate.from_template(template_3)
prompt_4 = ChatPromptTemplate.from_template(template_4)
prompt_5 = ChatPromptTemplate.from_template(template_5)


def init_knowledge_vector_store(filepath):
    EMBEDDING_MODEL = "model/text2vec_ernie/"
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    embeddings.client = sentence_transformers.SentenceTransformer(
        embeddings.model_name, device='cuda')
    loader = TextLoader(filepath)
    docs = loader.load()
    vector_store = FAISS.from_documents(docs, embeddings)
    return vector_store


def upload_file(files):
    vector_store = init_knowledge_vector_store(files.name)
    memory_text = ConversationSummaryBufferMemory(
        llm=llm, max_token_limit=4096)
    global QA_chain
    QA_chain = RetrievalQA.from_llm(llm=llm, retriever=vector_store.as_retriever(
        search_kwargs={"k": 2}), memory=memory_text)
    file_paths = [file.name for file in files]
    return file_paths


def Debatebytext_(prompt, help):
    msg = prompt
    response = QA_chain.run(msg)
    help.append((prompt, response))
    return help, help


def Debate_(prompt, help):
    msg = prompt_template.format_prompt(text=prompt).to_string()
    response = conversation_1.run(msg)
    help.append((prompt, response))
    return help, help


def Debate_classic(prompt, help):
    msg = prompt_template.format_prompt(text=prompt).to_string()
    response = conversation_2.run(msg)
    help.append((prompt, response))
    return help, help


def init_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_1
    for i in progress.tqdm(range(240), desc="ç«‹è®ºå€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def ask1_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_2
    for i in progress.tqdm(range(90), desc="ç›˜é—®å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def ask2_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_3
    for i in progress.tqdm(range(150), desc="è´¨è¯¢å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def again_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_4
    for i in progress.tqdm(range(150), desc="å¯¹è¾©å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def free_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_5
    for i in progress.tqdm(range(240), desc="è‡ªç”±è¾©å€’è®¡æ—¶ä¸­"):
        time.sleep(1)

title1 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒè¾©è®ºèµ›äº‹ï¼</center></h1>"
content1 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥ä½“éªŒé™æ—¶çš„è¾©è®ºå…¨æµç¨‹</center></h1>"
title2 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒç»å…¸è¾©è®ºèµ›äº‹ï¼</center></h1>"
content2 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥ä½“éªŒåœ¨ç»å…¸èµ›é¢˜ä¸Šä¸å¯èƒ½ä½ äº†è§£çš„å¤§ä½¬ä»¬å¯¹è¾©</center></h1>"
title3 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒè‡ªå®šä¹‰ææ–™èµ›äº‹ï¼</center></h1>"
content3 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥è‡ªè¡Œä¸Šä¼ æŸä½å¤§ä½¬çš„è¾©è®ºè®°å½•æ¥ä½“éªŒä¸ä»–ä»¬å¯¹è¾©</center></h1>"

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_page:
    gr.Markdown(title1)
    gr.Markdown(content1)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debate_, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç”¨æˆ·ç«‹è®º")
        ai_init_btn = gr.Button("AIç«‹è®º")
        ask_btn = gr.Button("ç”¨æˆ·è´¨è¯¢")
        ai_ask_btn = gr.Button("AIè´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask_btn.click(ask1_function, text, text2)
        ai_ask_btn.click(ask2_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)
        end_btn.click()

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_classic_page:
    gr.Markdown(title2)
    gr.Markdown(content2)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debate_classic, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç”¨æˆ·ç«‹è®º")
        ai_init_btn = gr.Button("AIç«‹è®º")
        ask_btn = gr.Button("ç”¨æˆ·è´¨è¯¢")
        ai_ask_btn = gr.Button("AIè´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask_btn.click(ask1_function, text, text2)
        ai_ask_btn.click(ask2_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)
        end_btn.click()

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_text_page:
    gr.Markdown(title3)
    gr.Markdown(content3)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debatebytext_, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç”¨æˆ·ç«‹è®º")
        ai_init_btn = gr.Button("AIç«‹è®º")
        ask_btn = gr.Button("ç”¨æˆ·è´¨è¯¢")
        ai_ask_btn = gr.Button("AIè´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask_btn.click(ask1_function, text, text2)
        ai_ask_btn.click(ask2_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)
        end_btn.click()
    with gr.Row():
        file_output = gr.File(label='è¯·ä¸Šä¼ ä½ æƒ³è¦, ç›®å‰æ”¯æŒtxtã€docxã€mdæ ¼å¼',
                          file_types=['.txt', '.md', '.docx'])
        upload_button = gr.UploadButton("Click to Upload a File", scale=1, file_types=[
                                    "text"])
        upload_button.upload(upload_file, upload_button, file_output)



demo = gr.TabbedInterface([Debate_page, Debate_classic_page, Debate_text_page], [
                          "è¾©è®ºèµ›äº‹",  "ç»å…¸è¾©è®ºèµ›äº‹","è‡ªå®šä¹‰ææ–™èµ›äº‹"])
demo.queue().launch()
