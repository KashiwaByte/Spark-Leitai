from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationChain
from langchain.chains import RetrievalQA
from utils.API import Spark_forlangchain
from utils.API import Spark_tools_forlangchain
import gradio as gr
from langchain.prompts import ChatPromptTemplate
from langchain.document_loaders import TextLoader
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
import sentence_transformers
import time
global llm
global conversation_1
global prompt_template

llm = Spark_forlangchain(n=10)
llm_tools = Spark_tools_forlangchain(n=10)

memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=4096)
conversation_1 = ConversationChain(llm=llm)

memory = ConversationSummaryBufferMemory(llm=llm_tools, max_token_limit=4096)
conversation_2 = ConversationChain(llm=llm_tools)

template_1 = "ç°åœ¨æ˜¯æ­£æ–¹ç«‹è®ºç¯èŠ‚ï¼Œè¯·ä½ å¬å–æ­£æ–¹ç«‹è®ºï¼Œå¹¶é’ˆå¯¹ç«‹è®ºè¿›è¡Œè´¨è¯¢ã€‚æ­£æ–¹ç«‹è®ºå†…å®¹å¦‚ä¸‹ï¼š{text}"
template_2 = ""
template_3 = ""
template_4 = ""
template_5 = ""
template_6 = ""
prompt_1 = ChatPromptTemplate.from_template(template_1)
prompt_2 = ChatPromptTemplate.from_template(template_2)
prompt_3 = ChatPromptTemplate.from_template(template_3)
prompt_4 = ChatPromptTemplate.from_template(template_4)
prompt_5 = ChatPromptTemplate.from_template(template_5)


def init_knowledge_vector_store(filepath):
    EMBEDDING_MODEL = "model/text2vec_ernie/"
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    embeddings.client = sentence_transformers.SentenceTransformer(
        embeddings.model_name, device='cuda')
    loader = TextLoader(filepath)
    docs = loader.load()
    vector_store = FAISS.from_documents(docs, embeddings)
    return vector_store


def upload_file(files):
    vector_store = init_knowledge_vector_store(files.name)
    memory_text = ConversationSummaryBufferMemory(
        llm=llm, max_token_limit=4096)
    global QA_chain
    QA_chain = RetrievalQA.from_llm(llm=llm, retriever=vector_store.as_retriever(
        search_kwargs={"k": 2}), memory=memory_text)
    file_paths = [file.name for file in files]
    return file_paths


def Debatebytext_(prompt, help):
    msg = prompt
    response = QA_chain.run(msg)
    help.append((prompt, response))
    return help, help


def Debate_(prompt, help):
    msg = prompt_template.format_prompt(text=prompt).to_string()
    response = conversation_1.run(msg)
    help.append((prompt, response))
    return help, help


def Debate_classic(prompt, help):
    msg = prompt_template.format_prompt(text=prompt).to_string()
    response = conversation_2.run(msg)
    help.append((prompt, response))
    return help, help


def init_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_1
    for i in progress.tqdm(range(240), desc="ç«‹è®ºå€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def ask1_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_2
    for i in progress.tqdm(range(90), desc="ç›˜é—®å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def ask2_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_3
    for i in progress.tqdm(range(150), desc="è´¨è¯¢å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def again_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_4
    for i in progress.tqdm(range(150), desc="å¯¹è¾©å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def free_function(text, progress=gr.Progress()):
    progress(0, desc="Starting...")
    time.sleep(1)
    prompt_template = prompt_5
    for i in progress.tqdm(range(240), desc="è‡ªç”±è¾©å€’è®¡æ—¶ä¸­"):
        time.sleep(1)

title1 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒè¾©è®ºèµ›äº‹ï¼</center></h1>"
content1 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥ä½“éªŒé™æ—¶çš„è¾©è®ºå…¨æµç¨‹</center></h1>"
title2 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒç»å…¸è¾©è®ºèµ›äº‹ï¼</center></h1>"
content2 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥ä½“éªŒåœ¨ç»å…¸èµ›é¢˜ä¸Šä¸å¯èƒ½ä½ äº†è§£çš„å¤§ä½¬ä»¬å¯¹è¾©</center></h1>"
title3 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒè‡ªå®šä¹‰ææ–™èµ›äº‹ï¼</center></h1>"
content3 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥è‡ªè¡Œä¸Šä¼ æŸä½å¤§ä½¬çš„è¾©è®ºè®°å½•æ¥ä½“éªŒä¸ä»–ä»¬å¯¹è¾©</center></h1>"
with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_page:
    gr.Markdown(title1)
    gr.Markdown(content1)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debate_, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç«‹è®º")
        ask1_btn = gr.Button("ç›˜é—®")
        ask2_btn = gr.Button("è´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask1_btn.click(ask1_function, text, text2)
        ask2_btn.click(ask2_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_classic_page:
    gr.Markdown(title2)
    gr.Markdown(content2)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debate_classic, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç«‹è®º")
        ask1_btn = gr.Button("ç›˜é—®")
        ask2_btn = gr.Button("è´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask1_btn.click(ask1_function, text, text2)
        ask2_btn.click(ask2_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_text_page:
    gr.Markdown(title3)
    gr.Markdown(content3)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debatebytext_, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç«‹è®º")
        ask1_btn = gr.Button("ç›˜é—®")
        ask2_btn = gr.Button("è´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask1_btn.click(ask1_function, text, text2)
        ask2_btn.click(ask2_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)
    with gr.Row():
        file_output = gr.File(label='è¯·ä¸Šä¼ ä½ æƒ³è¦, ç›®å‰æ”¯æŒtxtã€docxã€mdæ ¼å¼',
                          file_types=['.txt', '.md', '.docx'])
        upload_button = gr.UploadButton("Click to Upload a File", scale=1, file_types=[
                                    "text"])
        upload_button.upload(upload_file, upload_button, file_output)



demo = gr.TabbedInterface([Debate_page, Debate_classic_page, Debate_text_page], [
                          "è¾©è®ºèµ›äº‹",  "ç»å…¸è¾©è®ºèµ›äº‹","è‡ªå®šä¹‰ææ–™èµ›äº‹"])
demo.queue().launch()
