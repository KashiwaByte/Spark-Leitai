from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationChain
from langchain.chains import RetrievalQA
from utils.API import Spark_forlangchain
from utils.API import Spark_tools_forlangchain
import gradio as gr
from langchain.prompts import ChatPromptTemplate
from langchain.document_loaders import TextLoader
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
import sentence_transformers
import time
global llm
global conversation_1
llm = Spark_forlangchain(n=10)
llm_tools = Spark_tools_forlangchain(n=10)

memory1 = ConversationSummaryBufferMemory(llm=llm, max_token_limit=4096)
conversation_1 = ConversationChain(llm=llm, memory=memory1)

memory2 = ConversationSummaryBufferMemory(llm=llm_tools, max_token_limit=4096)
conversation_2 = ConversationChain(llm=llm_tools, memory=memory2)

memory3 = ConversationSummaryBufferMemory(llm=llm_tools, max_token_limit=4096)
template_1 = """
ç°åœ¨æ˜¯æ­£æ–¹ç«‹è®ºç¯èŠ‚ï¼Œè¯·ä½ å¬å–æ­£æ–¹ç«‹è®ºï¼Œå¹¶é’ˆå¯¹ç«‹è®ºè¿›è¡Œåé©³ã€‚
///æ­£æ–¹ç«‹è®ºå†…å®¹å¦‚ä¸‹ï¼š{text}///
åé©³éœ€è¦é€æ¡åé©³è§‚ç‚¹å’Œè®ºæ®ï¼Œå¹¶ä¸”è¦ç»™å‡ºè¯¦ç»†çš„ç†ç”±ã€‚
"""
template_2 = """
æˆ‘ä»¬æ­£åœ¨è¿›è¡Œä¸€åœºè¾©è®ºèµ›ï¼Œä½ éœ€è¦æ‰®æ¼”ä¸€ååæ–¹è¾©æ‰‹æ¥å’Œç”¨æˆ·å®Œæˆè¾©è®º
ç°åœ¨æ˜¯ä½ çš„ç«‹è®ºç¯èŠ‚ï¼Œä½ éœ€è¦åœ¨ä¸ç”¨æˆ·ç›¸åçš„æŒæ–¹ä¸Šç«‹è®ºï¼Œç»™å‡ºè‡ªå·±çš„è§‚ç‚¹,
å½“ç”¨æˆ·åé©³ä½ æ—¶ï¼Œä½ éœ€è¦ä¸ä»–è¾©é©³
///ç”¨æˆ·å›ç­”å¦‚ä¸‹ï¼š{text}///
"""
template_3 = """
æ¥ä¸‹æ¥æ˜¯å¯¹æ–¹å¯¹ä½ çš„ç›˜é—®ï¼Œè¯·ä½ çœŸè¯šçš„å›ç­”æ¯ä¸€ä¸ªé—®é¢˜
///ç”¨æˆ·ç›˜é—®å†…å®¹å¦‚ä¸‹ï¼š{text}///
"""
template_4 = """
æ¥ä¸‹æ¥æ˜¯ä½ å¯¹å¯¹æ–¹çš„ç›˜é—®ï¼Œè¯·ä½ é’ˆé”‹ç›¸å¯¹åœ°å¯¹ä»–æå‡ºé—®é¢˜ã€‚
///ç”¨æˆ·å›ç­”å¦‚ä¸‹ï¼š{text}///
"""
template_5 = """
ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„é€»è¾‘æ€§å¾ˆå¼ºçš„é¡¶çº§è¾©æ‰‹ï¼Œè¯·å¯¹æˆ‘çš„é™ˆè¿°è¿›è¡Œåé©³ï¼Œè¶Šè¯¦ç»†è¶Šå¥½ï¼Œåé©³éœ€è¦é€æ¡åé©³è§‚ç‚¹å’Œè®ºæ®ï¼Œå¹¶ä¸”è¦ç»™å‡ºè¯¦ç»†çš„ç†ç”±ï¼Œè´¨ç–‘æ•°æ®è®ºæ®è¦ç”¨ä¸Šå¸¸ç”¨çš„æ–¹æ³•å’Œå¥å¼ï¼Œä»æ•°æ®åˆç†æ€§ï¼Œæ ·æœ¬ä»£è¡¨æ€§ï¼Œç»Ÿè®¡æ–¹æ³•ï¼Œæ•°æ®è§£è¯»ç­‰å¤šä¸ªè§’åº¦è¿›è¡Œè€ƒè™‘ã€‚è´¨ç–‘å­¦ç†è®ºæ®è¦ä»æƒå¨æ€§ï¼Œè§£è¯»æ–¹å¼ï¼Œæ˜¯å¦æœ‰å¯¹æŠ—å­¦ç†ç­‰å¤šä¸ªè§’åº¦è¿›è¡Œè€ƒè™‘ã€‚
///å¦‚ä¸‹æ˜¯æˆ‘ä»¬çš„è¯é¢˜ä»¥åŠæˆ‘çš„è§‚ç‚¹ï¼š{text}///
"""
end_prompt = """
è¯·ä½ å¯¹æˆ‘ä»¬çš„å¯¹è¾©è¿‡ç¨‹è¿›è¡Œæ€»ç»“ï¼Œæ€»ç»“éœ€è¦åŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†ï¼š1.å¯¹è¾©ä¸»è¦é’ˆå¯¹ä»€ä¹ˆè¿›è¡Œè®¨è®ºã€‚2.è¯„ä»·æˆ‘çš„å¯¹è¾©èƒ½åŠ›ï¼Œéœ€è¦æ ¹æ®è¯„çº§åŸåˆ™ç»™å‡ºè¯„çº§ï¼Œå¹¶ä¸”ç»™å‡ºå…·ä½“ç†ç”±ã€‚è¯„çº§åŸåˆ™å¦‚ä¸‹ï¼šç­‰çº§ä¸€ï¼Œç¼ºä¹è®ºè¯çš„åé©³ï¼›ç­‰çº§äºŒï¼Œè‡ªè¯´è‡ªè¯çš„åé©³ï¼›ç­‰çº§ä¸‰ï¼Œé’ˆé”‹ç›¸å¯¹çš„åé©³ï¼›ç­‰çº§å››ï¼Œæ­£ä¸­è¦å®³çš„åé©³ã€‚3.æ ¹æ®æˆ‘çš„å¯¹è¾©èƒ½åŠ›æå‡ºä¸€å®šçš„å»ºè®®ã€‚
ç¤ºä¾‹å¦‚ä¸‹ï¼š
å¥½çš„ï¼Œæˆ‘æ¥å¯¹æˆ‘ä»¬çš„å¯¹è¾©è¿‡ç¨‹è¿›è¡Œæ€»ç»“ã€‚
åœ¨æˆ‘ä»¬çš„å¯¹è¾©è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦è®¨è®ºäº†åŠ¨ç‰©å›­æ˜¯å¦åº”è¯¥è¢«ç¦æ­¢ã€‚æˆ‘è®¤ä¸ºåŠ¨ç‰©å›­å¯¹åŠ¨ç‰©çš„ç¦åˆ©å’Œæƒåˆ©é€ æˆäº†è´Ÿé¢å½±å“ï¼Œè€Œæ‚¨åˆ™æå‡ºäº†ä¸€äº›è´¨ç–‘ï¼Œè®¤ä¸ºåŠ¨ç‰©å›­ä¸­çš„åŠ¨ç‰©å¯ä»¥äº«å—æ¯”é‡å¤–æ›´å®‰å…¨çš„ç”Ÿæ´»æ¡ä»¶ã€‚
æˆ‘è®¤ä¸ºæ‚¨çš„å¯¹è¾©èƒ½åŠ›å±äºç­‰çº§ä¸‰ï¼Œå³é’ˆé”‹ç›¸å¯¹çš„åé©³ã€‚æ‚¨èƒ½å¤Ÿå¯¹æˆ‘çš„è§‚ç‚¹æå‡ºä¸€äº›è´¨ç–‘å’Œåé©³ï¼Œå¹¶ä¸”èƒ½å¤Ÿç»™å‡ºä¸€äº›åˆç†çš„ç†ç”±ã€‚ä½†æ˜¯ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½ä¼šä½¿ç”¨ä¸€äº›ä¸å¤ªæ°å½“çš„ç±»æ¯”æ¥å½’è°¬æˆ‘çš„è§‚ç‚¹ï¼Œè¿™å¯èƒ½ä¼šå½±å“åˆ°å¯¹è¾©çš„è´¨é‡å’Œæ•ˆæœã€‚
é‰´äºæ‚¨çš„å¯¹è¾©èƒ½åŠ›ï¼Œæˆ‘è®¤ä¸ºæ‚¨å¯ä»¥è¿›ä¸€æ­¥æé«˜è‡ªå·±çš„è¾©è®ºæŠ€å·§ã€‚æ‚¨å¯ä»¥é€šè¿‡æ›´å¤šçš„é˜…è¯»å’Œå­¦ä¹ ï¼Œæé«˜è‡ªå·±çš„çŸ¥è¯†æ°´å¹³å’Œæ€ç»´èƒ½åŠ›ï¼Œä»è€Œæ›´å¥½åœ°è¿›è¡Œè®ºè¯å’Œåé©³ã€‚æ­¤å¤–ï¼Œåœ¨ä½¿ç”¨ç±»æ¯”å’Œæ¯”å–»æ—¶ï¼Œéœ€è¦æ›´åŠ è°¨æ…ï¼Œç¡®ä¿å®ƒä»¬èƒ½å¤Ÿæ°å½“åœ°è¡¨è¾¾æ‚¨çš„è§‚ç‚¹ï¼Œè€Œä¸ä¼šæ­ªæ›²æˆ–å½’è°¬å¯¹æ–¹çš„è§‚ç‚¹ã€‚
"""

common_prompt = ChatPromptTemplate.from_template
prompt_1 = ChatPromptTemplate.from_template(template_1)
prompt_2 = ChatPromptTemplate.from_template(template_2)
prompt_3 = ChatPromptTemplate.from_template(template_3)
prompt_4 = ChatPromptTemplate.from_template(template_4)
prompt_5 = ChatPromptTemplate.from_template(template_5)


def init_knowledge_vector_store(filepath):
    EMBEDDING_MODEL = "model/text2vec_ernie/"
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    embeddings.client = sentence_transformers.SentenceTransformer(
        embeddings.model_name, device='cuda')
    loader = TextLoader(filepath)
    docs = loader.load()
    vector_store = FAISS.from_documents(docs, embeddings)
    return vector_store


def upload_file(files):
    vector_store = init_knowledge_vector_store(files.name)
    global QA_chain
    QA_chain = RetrievalQA.from_llm(llm=llm, retriever=vector_store.as_retriever(
        search_kwargs={"k": 2}), memory=memory3)
    file_paths = [file.name for file in files]
    return file_paths


def Debatebytext_(prompt, help):
    msg = prompt_template.format_prompt(text=prompt).to_string()
    response = QA_chain.run(msg)
    help.append((prompt, response))
    return help, help


def Debate_(prompt, help):
    msg = prompt_template.format_prompt(text=prompt).to_string()
    response = conversation_1.run(msg)
    help.append((prompt, response))
    return help, help


def Debate_classic(prompt, help):
    msg = prompt_template.format_prompt(text=prompt).to_string()
    response = conversation_2.run(msg)
    help.append((prompt, response))
    return help, help


def init_function(text, progress=gr.Progress()):
    global prompt_template
    prompt_template = prompt_1
    progress(0, desc="Starting...")
    time.sleep(1)
    for i in progress.tqdm(range(240), desc="ç”¨æˆ·ç«‹è®ºå€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def ai_init_function(text, progress=gr.Progress()):
    global prompt_template
    prompt_template = prompt_1
    progress(0, desc="Starting...")
    time.sleep(1)
    for i in progress.tqdm(range(240), desc="AIç«‹è®ºå€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def ask_function(text, progress=gr.Progress()):
    global prompt_template
    prompt_template = prompt_2
    progress(0, desc="Starting...")
    time.sleep(1)
    for i in progress.tqdm(range(90), desc="ç”¨æˆ·è´¨è¯¢å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def ai_ask_function(text, progress=gr.Progress()):
    global prompt_template
    prompt_template = prompt_3
    progress(0, desc="Starting...")
    time.sleep(1)
    for i in progress.tqdm(range(150), desc="AIè´¨è¯¢å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def again_function(text, progress=gr.Progress()):
    global prompt_template
    prompt_template = prompt_4
    progress(0, desc="Starting...")
    time.sleep(1)
    for i in progress.tqdm(range(150), desc="å¯¹è¾©å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def free_function(text, progress=gr.Progress()):
    global prompt_template
    prompt_template = prompt_5
    progress(0, desc="Starting...")
    time.sleep(1)
    for i in progress.tqdm(range(240), desc="è‡ªç”±è¾©å€’è®¡æ—¶ä¸­"):
        time.sleep(1)


def end_function(text, help):
    msg = end_prompt
    response = conversation_1.run(msg)
    help.append((text, response))
    return help, help


title1 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒè¾©è®ºèµ›äº‹ï¼</center></h1>"
content1 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥ä½“éªŒé™æ—¶çš„è¾©è®ºå…¨æµç¨‹</center></h1>"
title2 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒç»å…¸è¾©è®ºèµ›äº‹ï¼</center></h1>"
content2 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥ä½“éªŒåœ¨ç»å…¸èµ›é¢˜ä¸Šä¸å¯èƒ½ä½ äº†è§£çš„å¤§ä½¬ä»¬å¯¹è¾©</center></h1>"
title3 = "<h1 style='font-size: 40px;'><center>æ¬¢è¿ä½“éªŒè‡ªå®šä¹‰ææ–™èµ›äº‹ï¼</center></h1>"
content3 = "<h1 style='font-size: 20px;'><center>æ‚¨å¯ä»¥è‡ªè¡Œä¸Šä¼ æŸä½å¤§ä½¬çš„è¾©è®ºè®°å½•æ¥ä½“éªŒä¸ä»–ä»¬å¯¹è¾©</center></h1>"

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_page:
    gr.Markdown(title1)
    gr.Markdown(content1)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debate_, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç”¨æˆ·ç«‹è®º")
        ai_init_btn = gr.Button("AIç«‹è®º")
        ask_btn = gr.Button("ç”¨æˆ·è´¨è¯¢")
        ai_ask_btn = gr.Button("AIè´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask_btn.click(ask_function, text, text2)
        ai_ask_btn.click(ai_ask_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)
        end_btn.click(end_function, [text, state], [chatbot, state])

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_classic_page:
    gr.Markdown(title2)
    gr.Markdown(content2)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debate_classic, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç”¨æˆ·ç«‹è®º")
        ai_init_btn = gr.Button("AIç«‹è®º")
        ask_btn = gr.Button("ç”¨æˆ·è´¨è¯¢")
        ai_ask_btn = gr.Button("AIè´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask_btn.click(ask_function, text, text2)
        ai_ask_btn.click(ai_ask_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)
        end_btn.click(end_function, [text, state], [chatbot, state])

with gr.Blocks(css="#chatbot{height:300px} .overflow-y-auto{height:500px}") as Debate_text_page:
    gr.Markdown(title3)
    gr.Markdown(content3)
    state = gr.State([])
    with gr.Row():
        chatbot = gr.Chatbot(elem_id="chatbot")
        text2 = gr.Textbox()
    with gr.Row():
        text = gr.Textbox()
        send = gr.Button("ğŸš€ å‘é€")
        send.click(Debatebytext_, [text, state], [chatbot, state])
    with gr.Row():
        init_btn = gr.Button("ç”¨æˆ·ç«‹è®º")
        ai_init_btn = gr.Button("AIç«‹è®º")
        ask_btn = gr.Button("ç”¨æˆ·è´¨è¯¢")
        ai_ask_btn = gr.Button("AIè´¨è¯¢")
        again_btn = gr.Button("å¯¹è¾©")
        free_btn = gr.Button("è‡ªç”±è¾©")
        end_btn = gr.Button("ç»“è¾©")
        init_btn.click(init_function, text, text2)
        ask_btn.click(ask_function, text, text2)
        ai_ask_btn.click(ai_ask_function, text, text2)
        again_btn.click(again_function, text, text2)
        free_btn.click(free_function, text, text2)
        end_btn.click(end_function, [text, state], [chatbot, state])
    with gr.Row():
        file_output = gr.File(label='è¯·ä¸Šä¼ ä½ æƒ³è¦, ç›®å‰æ”¯æŒtxtã€docxã€mdæ ¼å¼',
                              file_types=['.txt', '.md', '.docx'])
        upload_button = gr.UploadButton("Click to Upload a File", scale=1, file_types=[
            "text"])
        upload_button.upload(upload_file, upload_button, file_output)


demo = gr.TabbedInterface([Debate_page, Debate_classic_page, Debate_text_page], [
                          "è¾©è®ºèµ›äº‹",  "ç»å…¸è¾©è®ºèµ›äº‹", "è‡ªå®šä¹‰ææ–™èµ›äº‹"])
demo.queue(concurrency_count=3).launch()
